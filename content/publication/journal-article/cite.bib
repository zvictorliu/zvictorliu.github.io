@Article{Xie2023,
author={Xie, Mingye
and Liu, Zongwei
and Xiang, Suncheng
and Liu, Ting
and Fu, Yuzhuo},
title={Editing outdoor scenes with a large annotated synthetic dataset},
journal={Multimedia Tools and Applications},
year={2023},
month={Aug},
day={09},
abstract={With the continuous popularization of smartphones and their ever-evolving photographic capabilities, individuals can easily take a large number of photos in their daily lives, creating a natural impetus for image editing. With the ability of style-based GAN, images can be reasonably edited on specific semantics by manipulating in latent space of the generator, particularly for human facial photographs. However, such methods are heavily rely on the datasets with diverse data and rich semantic annotations at the same time. Unfortunately, there is no such dataset for outdoor scenes with diverse and complex structural content, which makes current editing methods almost ineffective. To overcome these challenges, we first construct an extensive synthetic outdoor scene dataset with fine-grained semantic annotations based on an automated process. Based on it, we propose an editing network dedicated to multi-class annotations that can efficiently edit specific attributes while preserving others as much as possible. Extensive experiments evince that our method achieves better performance in outdoor scene editing, especially in regards to distance and viewpoint across several outdoor scene datasets.},
issn={1573-7721},
doi={10.1007/s11042-023-16385-8},
url={https://doi.org/10.1007/s11042-023-16385-8}
}

